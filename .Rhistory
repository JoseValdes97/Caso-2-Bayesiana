LL[b]     <- sum(dt.scaled(x = y, df = k, mean = rep(theta, nj), sd = sqrt(rep(sig2, nj)),log = T))
}
# fin de la cadena
# salida
THETA <- as.data.frame(THETA[-c(1:1000),])
LL    <- as.data.frame(LL[-c(1:1000)])
colnames(THETA) <- c(paste0("theta", 1:m), paste0("sig2", 1:m),"mu", "tau2","beta")
colnames(LL) <- c("ll")
return(list(THETA = THETA, LL = LL))
}
#ajustar modelo
tictoc::tic()
set.seed(1856)
cadena1_M6 <- MCMC_6(y, B = 11000, nj, yb, s2)
MCMC_6 <- function(y, B, nj, yb, s2){
# tamaños
n <- sum(nj)
m <- length(nj)
# hiperparametros
mu0  <- 13.495
g20  <- 11.382
eta0 <- 1
t20  <- 1.182
al   <- 1
ab   <- 1
bb   <- 1.182
k    <- 3
# valores iniciales
theta <- yb
sig2  <- s2  # sigma_j^2
mu    <- mean(theta)
tau2  <- var(theta)
set.seed(2023)
beta  <- rgamma(1,shape = ab*0.5,rate = bb*0.5)
# almacenamiento
THETA <- matrix(data = NA, nrow = B, ncol = 2*m+3)
LL    <- matrix(data = NA, nrow = B, ncol = 1)
set.seed(2023)
for (b in 1:B) {
# Generar varsigma
varsig2   <- 1/rgamma(n = n, shape = 0.5*(k+1), rate = (0.5*(k*sig2 + (y - mean(y))^2)))
# actualizar theta
vtheta    <- 1/(1/tau2 + sum(1/varsig2))
theta     <- rnorm(n = m, mean = vtheta*(mu/tau2 + sum(y/varsig2)), sd = sqrt(vtheta))
# actualizar sig2
sig2      <- rgamma(n = m, shape = 0.5*(k*n+al), rate = (0.5*(k*sum(1/varsig2) + beta)))
# crear beta y actualizar
beta      <- rgamma(n = 1, shape=0.5*(ab+al*m),rate = 0.5*(sum(sig2)+bb))
# actualizar mu
vmu       <- 1/(1/g20 + m/tau2)
mu        <- rnorm(n = 1, mean = vmu*((mu0/g20)+(m*mean(theta)/tau2)), sd=sqrt(vmu))
# actualizar tau2
tau2      <- 1/rgamma(n = 1, shape = 0.5*(eta0 + m), rate = 0.5*(eta0*t20+(m-1)*var(theta)+m*(mean(theta)-mu)^2))
# almacenar
THETA[b,] <- c(theta, sig2, mu, tau2, beta)
# log-verosimilitud
LL[b]     <- sum(dt.scaled(x = y, df = k, mean = rep(theta, nj), sd = sqrt(rep(sig2, nj)),log = T))
}
# fin de la cadena
# salida
THETA <- as.data.frame(THETA[-c(1:1000),])
LL    <- as.data.frame(LL[-c(1:1000)])
colnames(THETA) <- c(paste0("theta", 1:m), paste0("sig2", 1:m),"mu", "tau2","beta")
colnames(LL) <- c("ll")
return(list(THETA = THETA, LL = LL))
}
#ajustar modelo
tictoc::tic()
set.seed(1856)
cadena1_M6 <- MCMC_6(y, B = 11000, nj, yb, s2)
MCMC_6 <- function(y, B, nj, yb, s2){
# tamaños
n <- sum(nj)
m <- length(nj)
# hiperparametros
mu0  <- 13.495
g20  <- 11.382
eta0 <- 1
t20  <- 1.182
al   <- 1
ab   <- 1
bb   <- 1.182
k    <- 3
# valores iniciales
theta <- yb
sig2  <- s2  # sigma_j^2
mu    <- mean(theta)
tau2  <- var(theta)
set.seed(2023)
beta  <- rgamma(1,shape = ab*0.5,rate = bb*0.5)
# almacenamiento
THETA <- matrix(data = NA, nrow = B, ncol = 2*m+3)
LL    <- matrix(data = NA, nrow = B, ncol = 1)
set.seed(2023)
for (b in 1:B) {
# Generar varsigma
varsig2   <- 1/rgamma(n = n, shape = 0.5*(k+1), rate = (0.5*(k*var(y) + (y - mean(y))^2)))
# actualizar theta
vtheta    <- 1/(1/tau2 + sum(1/varsig2))
theta     <- rnorm(n = m, mean = vtheta*(mu/tau2 + sum(y/varsig2)), sd = sqrt(vtheta))
# actualizar sig2
sig2      <- rgamma(n = m, shape = 0.5*(k*n+al), rate = (0.5*(k*sum(1/varsig2) + beta)))
# crear beta y actualizar
beta      <- rgamma(n = 1, shape=0.5*(ab+al*m),rate = 0.5*(sum(sig2)+bb))
# actualizar mu
vmu       <- 1/(1/g20 + m/tau2)
mu        <- rnorm(n = 1, mean = vmu*((mu0/g20)+(m*mean(theta)/tau2)), sd=sqrt(vmu))
# actualizar tau2
tau2      <- 1/rgamma(n = 1, shape = 0.5*(eta0 + m), rate = 0.5*(eta0*t20+(m-1)*var(theta)+m*(mean(theta)-mu)^2))
# almacenar
THETA[b,] <- c(theta, sig2, mu, tau2, beta)
# log-verosimilitud
LL[b]     <- sum(dt.scaled(x = y, df = k, mean = rep(theta, nj), sd = sqrt(rep(sig2, nj)),log = T))
}
# fin de la cadena
# salida
THETA <- as.data.frame(THETA[-c(1:1000),])
LL    <- as.data.frame(LL[-c(1:1000)])
colnames(THETA) <- c(paste0("theta", 1:m), paste0("sig2", 1:m),"mu", "tau2","beta")
colnames(LL) <- c("ll")
return(list(THETA = THETA, LL = LL))
}
#ajustar modelo
tictoc::tic()
set.seed(1856)
cadena1_M6 <- MCMC_6(y, B = 11000, nj, yb, s2)
tictoc::toc()
# cadenas
col <- RColorBrewer::brewer.pal(9,"Set1")[1:9]
yrange <- range(cadena1_M6$LL$ll)
# GrÃ¡fico
plot(cadena1_M6$LL$ll, type = "p", pch = ".", cex = 1.1, col = col[2], ylim = yrange, xlab = "Iteración", ylab = "Log-verosimilitud", main = "Modelo 6")
install.packages("nparLD")
power.t.test(n=200,sig.level = 0.05)
power.t.test(n=200,sig.level = 0.05, sd = 30,delta = 1)
set.seed(123)
antes <- rnorm(50, mean = 10, sd = 2)
despues <- rnorm(50, mean = 12, sd = 2)
# Realizar la prueba no paramétrica de Wilcoxon para datos pareados
result <- nparLD(x = antes, g = rep(1, 50), y = despues)
# Calcular el poder estadístico
power <- power.nparLD(result, n1 = 50)
# Imprimir el resultado
print(power)
library(pwr)
# Tamaño de muestra hipotético
n <- 200
# Media y desviación estándar hipotéticas de la variable de interés
media <- 50
desviacion <- 10
# Diferencia de medias que se desea detectar (tamaño del efecto esperado)
d <- 5
# Realiza el cálculo del poder estadístico
pwr.t.test(n = NULL, d = d, sig.level = 0.05, power = NULL, type = "two.sample", alternative = "two.sided", sd = desviacion)
# Realiza el cálculo del poder estadístico
pwr.t.test(n = NULL, d = d, sig.level = 0.05, power = NULL, type = "two.sample", alternative = "two.sided")
# Realiza el cálculo del poder estadístico
pwr.t.test(n = n, d = d, sig.level = 0.05, power = NULL, type = "two.sample", alternative = "two.sided")
# Diferencia de medias que se desea detectar (tamaño del efecto esperado)
d <- 0.5
# Realiza el cálculo del poder estadístico
pwr.t.test(n = n, d = d, sig.level = 0.05, power = NULL, type = "two.sample", alternative = "two.sided")
# Realiza el cálculo del poder estadístico
pwr.t.test(n = n, d = d, sig.level = 0.05, power = NULL, alternative = "two.sided")
# Realiza el cálculo del poder estadístico
pwr.t.test(n = n, d = d, sig.level = 0.05, power = NULL, type = "one.sample", alternative = "two.sided")
pwr.t.test(n = NULL, d = 0.05, sig.level = 0.05, power = 0.8, type = "one.sample", alternative = "two.sided")
pwr.t.test(n = NULL, d = 0.33, sig.level = 0.05, power = 0.8, type = "one.sample", alternative = "two.sided")
pwr.f2.test(u=2,v=1,f2=0.33,sig.level = 0.05)
pwr.f2.test(u=3,v=75-3-1,f2=0.33,sig.level = 0.05)
pwr.f2.test(u=3,v=75-3-1,f2=0.1,sig.level = 0.05)
pwr.f2.test(u=3,v=75-3-1,f2=0.22,sig.level = 0.05)
pwr.f2.test(u=3,v=75-3-1,f2=0.19,sig.level = 0.05)
pwr.f2.test(u=3,v=75-3-1,f2=0.17,sig.level = 0.05)
pwr.f2.test(u=3,v=75-3-1,f2=0.15,sig.level = 0.05)
pwr.f2.test(u=3,v=75-3-1,f2=0.16,sig.level = 0.05)
pwr.f2.test(u=3,v=75-3-1,f2=0.155,sig.level = 0.05)
pwr.f2.test(u=3,v=75-3-1,f2=0.1555,sig.level = 0.05)
pwr.f2.test(u=3,v=75-3-1,f2=0.151,sig.level = 0.05)
pwr.f2.test(u=3,v=75-3-1,f2=0.153,sig.level = 0.05)
pwr.f2.test(u=3,v=75-3-1,f2=0.154,sig.level = 0.05)
pwr.f2.test(u=3,v=75-3-1,f2=0.1538,sig.level = 0.05)
pwr.f2.test(u=3,v=75-3-1,f2=0.1537,sig.level = 0.05)
pwr.f2.test(u=3,v=75-3-1,f2=0.1536,sig.level = 0.05)
pwr.f2.test(u=3,v=75-3-1,f2=0.15369,sig.level = 0.05)
pwr.f2.test(u=3,v=75-3-1,f2=0.15366,sig.level = 0.05)
pwr.f2.test(u=3,v=75-3-1,f2=0.15361,sig.level = 0.05)
pwr.f2.test(u=3,v=75-3-1,f2=0.15362,sig.level = 0.05)
pwr.f2.test(u=3,v=75-3-1,f2=0.15361,sig.level = 0.05)
pwr.f2.test(u=3,v=75-3-1,f2=0.153611,sig.level = 0.05)
pwr.f2.test(u=3,v=75-3-1,f2=0.1536101,sig.level = 0.05)
pwr.f2.test(u=3,v=75-3-1,f2=0.1536109,sig.level = 0.05)
pwr.f2.test(u=3,v=75-3-1,f2=0.1536108,sig.level = 0.05)
pwr.f2.test(u=3,v=75-3-1,f2=0.1536107,sig.level = 0.05)
pwr.f2.test(u=3,v=75-3-1,f2=0.15361079,sig.level = 0.05)
pwr.f2.test(u=3,v=75-3-1,f2=0.15361078,sig.level = 0.05)
pwr.f2.test(u=3,v=75-3-1,f2=0.15361077,sig.level = 0.05)
pwr.f2.test(u=3,v=75-3-1,f2=0.15361076,sig.level = 0.05)
# Sexto modelo
#y_j <- aggregate(1/y ~ Data$Dominio, data = Data, sum)
MCMC_6 <- function(y, B, nj, yb){
# tamaños
n <- sum(nj)
m <- length(nj)
# hiperparametros
mu0  <- 13.495
g20  <- 11.382
eta0 <- 1
t20  <- 1.182
al   <- 1
ab   <- 1
bb   <- 1.182
k    <- 3
# valores iniciales
theta <- yb
set.seed(2023)
beta  <- rgamma(1,shape = ab*0.5,rate = bb*0.5)
sig2  <- rgamma(n=m,shape= al/2,rate = beta/2) #sigma_j^2
mu    <- mean(theta)
tau2  <- var(theta)
# almacenamiento
THETA <- matrix(data = NA, nrow = B, ncol = 2*m+3)
LL    <- matrix(data = NA, nrow = B, ncol = 1)
# auxiliares sumas paralos parametros
lims <- cumsum(nj)
set.seed(2023)
for (b in 1:B) {
# Generar varsigma
varsig2   <- 1/rgamma(n = n, shape = 0.5*(k+1), rate = 0.5*(k*rep(sig2,nj) + (y - rep(theta, nj))^2))
# sumas para la vtheta
acumu <- cumsum(1/varsig2)
sum1 <- acumu[lims] - c(0,acumu[lims[-length(lims)]])
#vtheta
vtheta <- 1/(1/tau2 + sum1)
# sumas para mediatheta
acumu <- cumsum(y/varsig2)
sum2 <- acumu[lims] - c(0,acumu[lims[-length(lims)]])
# actualizar theta
theta     <- rnorm(n = m, mean = vtheta*(mu/tau2 + sum2), sd = sqrt(vtheta))
# actualizar mu
vmu       <- 1/(1/g20 + m/tau2)
mu        <- rnorm(n = 1, mean = vmu*((mu0/g20)+(m*mean(theta)/tau2)), sd=sqrt(vmu))
# actualizar tau2
tau2      <- 1/rgamma(n = 1, shape = 0.5*(eta0 + m), rate = 0.5*(eta0*t20+(m-1)*var(theta)+m*(mean(theta)-mu)^2))
# actualizar sigma_j^2
sig2      <- rgamma(n = m, shape = 0.5*((k*nj)+al), rate = (0.5*(k*sum1 + beta)))
# crear beta y actualizar
beta      <- rgamma(n = 1, shape=0.5*(ab+(al*m)),rate = 0.5*(sum(sig2)+bb))
# almacenar
THETA[b,] <- c(theta, sig2, mu, tau2, beta)
# log-verosimilitud
LL[b]     <- sum(dt.scaled(x = y, df = k, mean = rep(theta, nj), sd = sqrt(rep(sig2, nj)),log = T))
}
# fin de la cadena
# salida
THETA <- as.data.frame(THETA[-c(1:1000),])
LL    <- as.data.frame(LL[-c(1:1000)])
colnames(THETA) <- c(paste0("theta", 1:m), paste0("sig2", 1:m),"mu", "tau2","beta")
colnames(LL) <- c("ll")
return(list(THETA = THETA, LL = LL))
}
suppressMessages(suppressWarnings(library(dplyr)))
knitr::opts_chunk$set(echo = TRUE)
#ajustar modelo
tictoc::tic()
set.seed(1856)
cadena1_M6 <- MCMC_6(y, B = 11000, nj, yb, s2)
#ajustar modelo
tictoc::tic()
set.seed(1856)
cadena1_M6 <- MCMC_6(y, B = 11000, nj, yb)
library(metRology)
#ajustar modelo
tictoc::tic()
set.seed(1856)
cadena1_M6 <- MCMC_6(y, B = 11000, nj, yb)
tictoc::toc()
# cadenas
col <- RColorBrewer::brewer.pal(9,"Set1")[1:9]
yrange <- range(cadena1_M6$LL$ll)
# GrÃ¡fico
plot(cadena1_M6$LL$ll, type = "p", pch = ".", cex = 1.1, col = col[2], ylim = yrange, xlab = "Iteración", ylab = "Log-verosimilitud", main = "Modelo 6")
# cadenas
col <- RColorBrewer::brewer.pal(9,"Set1")[1:9]
yrange <- range(cadena1_M6$LL$ll)
# GrÃ¡fico
plot(cadena1_M6$LL$ll, type = "p", pch = "*", cex = 1.1, col = col[2], ylim = yrange, xlab = "Iteración", ylab = "Log-verosimilitud", main = "Modelo 6")
View(THETA)
THETA
cadena1_M6
theta_est  <- cadena1_M6[,1:25]
theta_est  <- cadena1_M6[,c(1:25)]
sigma2_est <- cadena1_M6[,c(26:50)]
theta_est  <- cadena1_M6[c(1:25)]
head(theta_est)
head(theta_est)
tail(theta_est)
theta_est  <- cadena1_M6$THETA[c(1:25)]
theta_est
sigma2_est <- cadena1_M6$THETA[c(26:50)]
sigma2_est
theta_est  <- cadena1_M6$THETA[c(1:25)]
sigma2_est <- cadena1_M6$THETA[c(26:50)]
theta_est  <- colMeans(theta_est)
sigma2_est <- colMeans(sigma2_est)
sigma2_est
theta_est
theta_est  <- cadena1_M6$THETA[c(1:25)]
sigma2_est <- cadena1_M6$THETA[c(26:50)]
theta_est  <- colMeans(theta_est)
sigma2_est <- colMeans(sigma2_est)
theta_est  <- as.matrix(theta_est)
sigma2_est <- as.matrix(sigma2_est)
theta_est
arreglo    <- as.matrix(theta_est,sigma2_est); arreglo
arreglo    <- as.data.frame(theta_est,sigma2_est); arreglo
arreglo    <- as.data.frame(theta_est=theta_est,sigma2_est=sigma2_est); arreglo
arreglo    <- data.frame(theta_est,sigma2_est); arreglo
theta_est  <- cadena1_M6$THETA[c(1:25)]
sigma2_est <- cadena1_M6$THETA[c(26:50)]
theta_est  <- colMeans(theta_est)
sigma2_est <- colMeans(sigma2_est)
theta_est  <- as.matrix(theta_est)
sigma2_est <- as.matrix(sigma2_est)
arreglo    <- data.frame(theta_est,sigma2_est); arreglo
rownames(arreglo) <- NULL
arreglo
theta_est  <- cadena1_M6$THETA[c(1:25)]
sigma2_est <- sqrt(cadena1_M6$THETA[c(26:50)])
theta_est  <- colMeans(theta_est)
sigma2_est <- colMeans(sigma2_est)
theta_est  <- as.matrix(theta_est)
sigma2_est <- as.matrix(sigma2_est)
arreglo    <- data.frame(theta_est,sigma2_est); arreglo
rownames(arreglo) <- NULL
theta_est  <- cadena1_M6$THETA[c(1:25)]
sigma2_est <- sqrt(cadena1_M6$THETA[c(26:50)])
theta_est  <- colMeans(theta_est)
sigma2_est <- colMeans(sigma2_est)
theta_est  <- as.matrix(theta_est)
sigma2_est <- as.matrix(sigma2_est)
arreglo    <- data.frame(theta_est,sigma2_est); arreglo
rownames(arreglo) <- NULL
arreglo
posicion <- c(0
1800,
posicion <- c(0,
1800,
7200,
9000,
10800,
18000,
19800,
28800
)
vm <- c(11.11111111,
5.555555556,
0,
5.555555556,
-9.722222222,
0,
5.555555556,
)
vm <- c(11.11111111,
5.555555556,
0,
5.555555556,
-9.722222222,
0,
5.555555556
)
tiempo <- c(0,
1800,
7200,
9000,
10800,
18000,
19800,
28800
)
vm <- c(11.11111111,
5.555555556,
0,
5.555555556,
-9.722222222,
0,
5.555555556
)
library(ggplot2)
# Crear un data frame con los datos de tiempo y velocidad
data <- data.frame(tiempo = c(0, 1, 2, 3, 4),
velocidad = c(0, 10, 20, 30, 40))
# Crear el gráfico utilizando ggplot2
ggplot(data, aes(x = tiempo, y = velocidad)) +
geom_line() +
geom_segment(aes(x = 0, xend = 4, y = 0, yend = 40), linetype = "dashed") +
geom_segment(aes(x = 0, xend = 4, y = 40, yend = 40), linetype = "solid") +
geom_segment(aes(x = 0, xend = 4, y = 0, yend = 0), linetype = "solid") +
geom_segment(aes(x = 4, xend = 4, y = 0, yend = 40), linetype = "solid") +
geom_hline(yintercept = 0:40, linetype = "solid") +
ylim(c(0, 40)) +
theme_classic() +
theme(axis.title = element_blank(),
axis.text = element_blank(),
axis.ticks = element_blank(),
panel.grid = element_blank(),
panel.background = element_rect(fill = "white"))
rm(tiempo,vm)
theta_est  <- cadena1_M6$THETA[c(1:25)]
sigma2_est <- sqrt(cadena1_M6$THETA[c(26:50)])
theta_est  <- colMeans(theta_est)
sigma2_est <- colMeans(sigma2_est)
arreglo    <- data.frame(theta_est,sigma2_est); arreglo
rownames(arreglo) <- NULL
arreglo
# Paso 1: Calcular la matriz de distancias entre los dominios
dist_matrix <- dist(arreglo)
# Paso 2: Realizar la agrupación jerárquica
hclust_result <- hclust(dist_matrix, method = "complete")
# Paso 3: Obtener la segmentación en cuatro grupos
groups <- cutree(hclust_result, k = 4)
# Paso 4: Mostrar los resultados
results <- data.frame(Dominio = rownames(arreglo), Grupo = groups)
print(results)
theta_est  <- cadena1_M6$THETA[c(1:25)]
sigma2_est <- sqrt(cadena1_M6$THETA[c(26:50)])
theta_est  <- colMeans(theta_est)
sigma2_est <- colMeans(sigma2_est)
arreglo    <- data.frame(theta_est,sigma2_est); arreglo
rownames(arreglo) <- NULL
# Paso 1: Calcular la matriz de distancias entre los dominios
dist_matrix <- dist(arreglo)
# Paso 2: Realizar la agrupación jerárquica
hclust_result <- hclust(dist_matrix, method = "complete")
# Paso 3: Obtener la segmentación en cuatro grupos
groups <- cutree(hclust_result, k = 4)
# Paso 4: Mostrar los resultados
results <- data.frame(Dominio = rownames(arreglo), Grupo = groups)
print(results)
theta_est  <- exp(cadena1_M6$THETA[c(1:25)])
sigma2_est <- exp(sqrt(cadena1_M6$THETA[c(26:50)]))
theta_est  <- colMeans(theta_est)
sigma2_est <- colMeans(sigma2_est)
arreglo    <- data.frame(theta_est,sigma2_est); arreglo
rownames(arreglo) <- NULL
# Paso 1: Calcular la matriz de distancias entre los dominios
dist_matrix <- dist(arreglo)
# Paso 2: Realizar la agrupación jerárquica
hclust_result <- hclust(dist_matrix, method = "complete")
# Paso 3: Obtener la segmentación en cuatro grupos
groups <- cutree(hclust_result, k = 4)
# Paso 4: Mostrar los resultados
results <- data.frame(Dominio = rownames(arreglo), Grupo = groups)
print(results)
theta_est  <- (cadena1_M6$THETA[c(1:25)]-mean(cadena1_M6$THETA[c(1:25)]))/sd(cadena1_M6$THETA[c(1:25)])
mean(cadena1_M6$THETA[c(1:25)]))
mean(cadena1_M6$THETA[c(1:25)])
theta_est  <- (cadena1_M6$THETA[c(1:25)]-colMeans(cadena1_M6$THETA[c(1:25)]))/sd(cadena1_M6$THETA[c(1:25)])
colMeans(cadena1_M6$THETA[c(1:25)])
theta  <- cadena1_M6$THETA[c(1:25)]
sigma2 <- sqrt(cadena1_M6$THETA[c(26:50)])
theta_est  <- (colMeans(theta)-mean(theta))/sd(theta)
theta  <- cadena1_M6$THETA[c(1:25)]
sigma2 <- sqrt(cadena1_M6$THETA[c(26:50)])
theta_est  <- (colMeans(theta)-mean(colMeans(theta)))/sd(colMeans(theta))
sigma2_est <- (colMeans(sigma2)-mean(colMeans(sigma2)))/sd(colMeans(sigma2))
arreglo    <- data.frame(theta_est,sigma2_est); arreglo
rownames(arreglo) <- NULL
# Paso 1: Calcular la matriz de distancias entre los dominios
dist_matrix <- dist(arreglo)
# Paso 2: Realizar la agrupación jerárquica
hclust_result <- hclust(dist_matrix, method = "complete")
# Paso 3: Obtener la segmentación en cuatro grupos
groups <- cutree(hclust_result, k = 4)
# Paso 4: Mostrar los resultados
results <- data.frame(Dominio = rownames(arreglo), Grupo = groups)
print(results)
theta  <- cadena1_M6$THETA[c(1:25)]
sigma2 <- sqrt(cadena1_M6$THETA[c(26:50)])
theta_est  <- colMeans(theta)
sigma2_est <- colMeans(sigma2)
arreglo    <- data.frame(theta_est,sigma2_est); arreglo
rownames(arreglo) <- NULL
arreglo<-scale(arreglo); arreglo
# Paso 1: Calcular la matriz de distancias entre los dominios
dist_matrix <- dist(arreglo)
# Paso 2: Realizar la agrupación jerárquica
hclust_result <- hclust(dist_matrix, method = "complete")
# Paso 3: Obtener la segmentación en cuatro grupos
groups <- cutree(hclust_result, k = 4)
# Paso 4: Mostrar los resultados
results <- data.frame(Dominio = rownames(arreglo), Grupo = groups)
theta  <- cadena1_M6$THETA[c(1:25)]
sigma2 <- sqrt(cadena1_M6$THETA[c(26:50)])
theta_est  <- colMeans(theta)
sigma2_est <- colMeans(sigma2)
arreglo    <- data.frame(theta_est,sigma2_est); arreglo
rownames(arreglo) <- NULL
arreglo <-as.matrix(scale(arreglo)); arreglo
# Paso 1: Calcular la matriz de distancias entre los dominios
dist_matrix <- dist(arreglo)
# Paso 2: Realizar la agrupación jerárquica
hclust_result <- hclust(dist_matrix, method = "complete")
# Paso 3: Obtener la segmentación en cuatro grupos
groups <- cutree(hclust_result, k = 4)
# Paso 4: Mostrar los resultados
results <- data.frame(Dominio = rownames(arreglo), Grupo = groups)
results
# Paso 4: Mostrar los resultados
results <- data.frame(Dominio = rownames(arreglo), Grupo = groups)
rownames(arreglo)
scale(arreglo)
