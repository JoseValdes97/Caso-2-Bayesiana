---
title: "Caso 2(Principal)"
author: "Joan Lamprea y Jose Valdes"
date: "2023-05-04"
output: html_document
---

```{r setup, include=FALSE}
suppressMessages(suppressWarnings(library(dplyr)))
suppressMessages(suppressWarnings(library(metRology)))
knitr::opts_chunk$set(echo = TRUE)
#modelo 1
source("D:/jose/CasoBayes2/modelo_1.R")
#modelo 2
source("D:/jose/CasoBayes2/modelo_2.R")
#modelo 3
source("D:/jose/CasoBayes2/modelo_3.R")
#modelo 4
source("D:/jose/CasoBayes2/modelo_4.R")
#modelo 5
source("D:/jose/CasoBayes2/modelo_5.R")
#modelo 6
source("D:/jose/CasoBayes2/modelo_6.R")
```

# Caso 2 de bayesiana

## Base de datos

```{r}
# cargar los datos
load("D:/jose/CasoBayes2/Personas.Rdata")
# mira Na en ingtot
sum(is.na(dat$ingtot))
```
Teniendo encuenta lo anterior extraeremos de la base de datos las varibles
para el caso las cuales son **dominio** y **ingtot**. Organizamos los datos
teniendo encuenta que:  

 1. Recordamos que la función log tiene base $e$.  
 2. La varaible **dominio** es un factor 

```{r}
#datos que voy a usar
Data <- data.frame(dat$dominio, dat$ingtot)
#nombres
names(Data) <- c("Dominio","Ingtot")
# pasamos los Ingtot a escala logaritmica
Data[,2] <- log(Data$Ingtot)
# presentar datos
head(Data)
# comprobar media,varianza  y precisión
mean(Data$Ingtot)
var(Data$Ingtot)
1/var(Data$Ingtot)
# volver factor domionio
class(Data$Dominio)
Data[,1] <- as.factor(Data$Dominio)
summary(Data$Dominio)
#boxplot
boxplot(Data$Ingtot)
```

Ahora con esto obtendremos los datos que nos son relevantes para eltrabajo  
desde la base de datos cómo:

```{r}
# m <- Cantidad de dominios (Departamentos)
m <- length(table(Data$Dominio))
m
# n <- número de individuos
n <- sum(table(Data$Dominio))
n
# y <- vector con los datos
y <- Data$Ingtot
head(y)
```

Obtendremos una tabla con los estadísticos necesarios por dominio para trabajar con las distribuciones condicionales completas y tener una idea de los datos.

 1. la función **n()** solo funciona dentro de una funcion actual como summarise     en el estado actual y devuelve el tamaño del grupo

```{r}
# tabla con los estadisticos
Estadisticos <- Data %>% 
      group_by(Dominio) %>% 
      summarise(Dominio = unique(Dominio), nj = n(), yb = mean(Ingtot),
                s2 = var(Ingtot))
head(Estadisticos)
# almacenar info importante
nj <- Estadisticos$nj
yb <- Estadisticos$yb
s2 <- Estadisticos$s2
```

## Modelo 1

Hiperparámetros del modelo.

$\textsf{M}_1$: $\mu_0 = 13.495$, $\gamma_0^2 = 11.382$, $\nu_0 = 1$, $\sigma^2_0 = 1.182$.

Ejecución del modelo

```{r}
#ajustar modelo
tictoc::tic()
set.seed(1856)
cadena1_M1 <- MCMC_1(y,B = 11000)
tictoc::toc()
```
### Convergencia

Usaremos la log-verosimilitud para mirar la convergencia de la cadena

```{r}
# Gráfico
yrange <- range(cadena1_M1$LL$ll)
plot(cadena1_M1$LL$ll, type = "p", pch = 20, cex = 0.8, col = "darkblue", ylim = yrange, xlab = "Iteracion",ylab = "Log-verosimilitud", main = "Modelo 1")
```

## Modelo 2

Hiperparámetros del modelo.

$\textsf{M}_2$: $\mu_0 = 13.495$, $\gamma_0^2 = 11.382$, $\eta_0 = 1$, $\tau^2_0 = 1.182$, $\nu_0 = 1$, $\sigma^2_0 = 1.182$.

Ejecución del modelo

```{r}
#ajustar modelo
tictoc::tic()
set.seed(1856)
cadena1_M2 <- MCMC_2(y, B = 11000, nj, yb, s2)
tictoc::toc()
```
### Convergencia

Usaremos la log-verosimilitud para mirar la convergencia de la cadena

```{r}
# Gráfico
yrange <- range(cadena1_M2$LL$ll)
plot(cadena1_M2$LL$ll, type = "p", pch = 20, cex = 0.8, col = "cyan", ylim = yrange, xlab = "Iteracion",ylab = "Log-verosimilitud", main = "Modelo 2")
```


## Modelo 3

Hiperparámetros del modelo.

$\textsf{M}_3$: $\mu_0 = 13.495$, $\gamma_0^2 = 11.382$, $\eta_0 = 1$, $\tau^2_0 = 1.182$, $\nu = 1$, $\alpha_0 = 1$, $\beta_0 = 0.846$.

Ejecución del modelo

```{r}
#ajustar modelo
tictoc::tic()
set.seed(1856)
cadena1_M3 <- MCMC_3(y,B = 11000, nj, yb, s2)
tictoc::toc()
```
### Convergencia

Usaremos la log-verosimilitud para mirar la convergencia de la cadena

```{r}
# Gráfico
yrange <- range(cadena1_M3$LL$ll)
plot(cadena1_M3$LL$ll, type = "p", pch = 20, cex = 0.8, col = "brown", ylim = yrange,  xlab = "Iteracion",ylab = "Log-verosimilitud", main = "Modelo 3")
```

## Modelo 4

Hiperparámetros del modelo.

$\textsf{M}_4$: $\mu_0 = 13.495$, $\gamma_0^2 = 11.382$, $\alpha_0 = 1$, $\beta_0 = 0.846$, $\kappa = 3$.

Ejecución del modelo

```{r}
#ajustar modelo
tictoc::tic()
set.seed(1856)
cadena1_M4 <- MCMC_4(y,B = 11000, nj)
tictoc::toc()
```
### Convergencia

Usaremos la log-verosimilitud para mirar la convergencia de la cadena

```{r}
# Gráfico
yrange <- range(cadena1_M4$LL$ll)
plot(cadena1_M4$LL$ll, type = "p", pch = 20, cex = 0.8, col = "gold", ylim = yrange, xlab = "Iteracion",ylab = "Log-verosimilitud", main = "Modelo 4")
```

## Modelo 5

Hiperparámetros del modelo.
 
$\textsf{M}_5$: $\mu_0 = 13.495$, $\gamma_0^2 = 11.382$, $\eta_0 = 1$, $\tau^2_0 = 1.182$, $\alpha_0 = 1$, $\beta_0 = 0.846$, $\kappa = 3$.

Ejecución del modelo

```{r}
#ajustar modelo
tictoc::tic()
set.seed(1856)
cadena1_M5 <- MCMC_5(y,B = 11000, nj, yb)
tictoc::toc()
```

### Convergencia

Usaremos la log-verosimilitud para mirar la convergencia de la cadena

```{r}
# Gráfico
yrange <- range(cadena1_M5$LL$ll)
plot(cadena1_M5$LL$ll, type = "p", pch = 20, cex = 0.8, col = "magenta", ylim = yrange,  xlab = "Iteracion",ylab = "Log-verosimilitud", main = "Modelo 5")
```

## Modelo 6

Hiperparámetros del modelo.
 
$\textsf{M}_6$: $\mu_0 = 13.495$, $\gamma_0^2 = 11.382$, $\eta_0 = 1$, $\tau^2_0 = 1.182$, $\alpha = 1$, $a_\beta = 1$, $b_\beta =  1.182$, $\kappa = 3$.

Ejecución del modelo

```{r}
#ajustar modelo
tictoc::tic()
set.seed(1856)
cadena1_M6 <- MCMC_6(y,B = 11000, nj, yb)
tictoc::toc()
```


### Convergencia

Usaremos la log-verosimilitud para mirar la convergencia de la cadena

```{r}
# Gráfico
yrange <- range(cadena1_M6$LL$ll)
plot(cadena1_M6$LL$ll, type = "p", pch = 20, cex = 0.8, col = "darkgreen", ylim = yrange, xlab = "Iteracion",ylab = "Log-verosimilitud", main = "Modelo 6")
```


### modelos en un solo plot

```{r}
# Gráfico
par(mfrow = c(1,1), mar = c(2.75,2.75,1.5,0.5), mgp=c(1.7,0.7,0))
#modelos normal
yrange <- range(cadena1_M1$LL$ll, cadena1_M2$LL$ll,cadena1_M3$LL$ll,cadena1_M4$LL$ll, cadena1_M5$LL$ll,cadena1_M6$LL$ll)
plot(cadena1_M1$LL$ll, type = "p", pch = 20, cex = 0.5, col = "darkblue", ylim = yrange, xlab = "Iteracion",ylab = "Log-verosimilitud", main = "Modelos")
lines(cadena1_M2$LL$ll, type = "p",pch = 20, cex = 0.5,col = "cyan")
lines(cadena1_M3$LL$ll, type = "p", pch = 20, cex = 0.5,col = "brown")
#modelos t
#yrange <- range(cadena1_M4$LL$ll, cadena1_M5$LL$ll,cadena1_M6$LL$ll)
#plot(cadena1_M4$LL$ll, type = "p", pch = 20, cex = 0.6, col = "lightblue", ylim = yrange,  xlab = "Iteración",ylab = "Log-verosimilitud", main = "Modelos t")
lines(cadena1_M4$LL$ll, type = "p", pch = 20, cex = 0.5,col = "gold")
lines(cadena1_M5$LL$ll, type = "p", pch = 20, cex = 0.5,col = "magenta")
lines(cadena1_M6$LL$ll, type = "p", pch = 20, cex = 0.5,col = "darkgreen")
```


```{r}
# Gráfico
par(mfrow = c(1,2), mar = c(2.75,2.75,1.5,0.5), mgp=c(1.7,0.7,0))
#modelos normal
yrange <- range(cadena1_M1$LL$ll, cadena1_M2$LL$ll,cadena1_M3$LL$ll)
plot(cadena1_M1$LL$ll, type = "p", pch = 20, cex = 0.5, col = "darkblue", ylim = yrange, xlab = "Iteracion",ylab = "Log-verosimilitud", main = "Modelos")
lines(cadena1_M2$LL$ll, type = "p",pch = 20, cex = 0.5,col = "cyan")
lines(cadena1_M3$LL$ll, type = "p", pch = 20, cex = 0.5,col = "brown")
#modelos t
yrange <- range(cadena1_M4$LL$ll, cadena1_M5$LL$ll,cadena1_M6$LL$ll)
plot(cadena1_M4$LL$ll, type = "p", pch = 20, cex = 0.6, col = "gold", ylim = yrange,  xlab = "Iteracion",ylab = "Log-verosimilitud", main = "Modelos t")
#lines(cadena1_M4$LL$ll, type = "p", pch = 20, cex = 0.5,col = "gold")
lines(cadena1_M5$LL$ll, type = "p", pch = 20, cex = 0.5,col = "magenta")
lines(cadena1_M6$LL$ll, type = "p", pch = 20, cex = 0.5,col = "darkgreen")
```

## Comparación de modelos

primero hacremos un analsis de los modelos para su densidad

```{r}
#gráfico fondo
plot(x = NA, y = NA, ylab = "Densidad", xlab = "Log-verosimilitud", cex.axis = 0.7, xlim = range(as.numeric(cadena1_M5$LL$ll), as.numeric(cadena1_M6$LL$ll),as.numeric(cadena1_M2$LL$ll),as.numeric(cadena1_M3$LL$ll)), ylim = c(0,0.12))
# modelo dos
hist(as.numeric(cadena1_M2$LL$ll), freq = F, add = T, col = "lightblue", border = "lightblue")
lines(density(as.numeric(cadena1_M2$LL$ll)), col = "blue")
# modelos tres
hist(as.numeric(cadena1_M3$LL$ll), freq = F, add = T, col = "burlywood", border = "burlywood")
lines(density(as.numeric(cadena1_M3$LL$ll)), col = "brown")
# modelos cinco
hist(as.numeric(cadena1_M5$LL$ll), freq = F, add = T, col = "mistyrose", border = "mistyrose")
lines(density(as.numeric(cadena1_M5$LL$ll)), col = "magenta")
# modelos seis
hist(as.numeric(cadena1_M6$LL$ll), freq = F, add = T, col = "lightgreen", border = "lightgreen")
lines(density(as.numeric(cadena1_M6$LL$ll)), col = "green")
# cuadro legendario
legend("top", legend = c("Modelo 2","Modelo 3","Modelo 5","Modelo 6"), fill = c("lightblue", "burlywood", "mistyrose", "lightgreen"), border = c("blue", "brown", "magenta", "green"), bty = "n")
```

Notamos que los modelos t tienen una **log-verosimilitud** más grande que los modelos **normales**, también se puede ver que destaca el modelo **modelo 6** por encima de los demas con el valor más alto de **log-vegosimilitud promedio**

### Compración modelos

Usaremos el DIC para cada uno de los modelos

#### modelo 1

```{r}
# log-verosimilitud
LP1 <- as.numeric(cadena1_M1$LL$ll)
# estimación theta_bayes
theta_hat  <- mean(cadena1_M1$THETA$theta)
# estimación sig2_bayes
sigma2_hat <- mean(cadena1_M1$THETA$sig2)
# log-verosimilitud con parámetros estimacdos
lpyth_m1   <- sum(dnorm(x = y, mean = theta_hat, sd = sqrt(sigma2_hat), log = T))
lpyth_m1
# oenalización por cantidad de parámetros
pDIC_m1    <- 2*(lpyth_m1 - mean(LP1))
pDIC_m1
# Criterio DIC
DIC_m1     <- -2*lpyth_m1 + 2*pDIC_m1
DIC_m1
```

#### modelo 2

```{r}
# log-verosimilitud
LP1 <- as.numeric(cadena1_M2$LL$ll)
# estimación theta_bayes
theta_hat  <- colMeans(cadena1_M2$THETA[,1:m])
# estimación sig2_bayes
sigma2_hat <- mean(cadena1_M2$THETA$sig2)
# log-verosimilitud con parámetros estimacdos
lpyth_m2   <- sum(dnorm(x = y, mean = rep(theta_hat,nj), sd = sqrt(sigma2_hat), log = T))
lpyth_m2
# oenalización por cantidad de parámetros
pDIC_m2    <- 2*(lpyth_m2 - mean(LP1))
pDIC_m2
# Criterio DIC
DIC_m2     <- -2*lpyth_m2 + 2*pDIC_m2
DIC_m2
```

#### modelo 3

```{r}
# log-verosimilitud
LP1 <- as.numeric(cadena1_M3$LL$ll)
# estimación theta_bayes
theta_hat  <- colMeans(cadena1_M3$THETA[,1:m])
# estimación sig2_bayes
sigma2_hat <- colMeans(cadena1_M3$THETA[,(m+1):(2*m)])
# log-verosimilitud con parámetros estimacdos
lpyth_m3   <- sum(dnorm(x = y, mean = rep(theta_hat,nj), sd = sqrt(rep(sigma2_hat, nj)), log = T))
lpyth_m3
# oenalización por cantidad de parámetros
pDIC_m3    <- 2*(lpyth_m3 - mean(LP1))
pDIC_m3
# Criterio DIC
DIC_m3     <- -2*lpyth_m3 + 2*pDIC_m3
DIC_m3
```

#### modelo 4

```{r}
# log-verosimilitud
LP1 <- as.numeric(cadena1_M4$LL$ll)
# estimación theta_bayes
theta_hat  <- mean(cadena1_M4$THETA$theta)
# estimación sig2_bayes
sigma2_hat <- mean(cadena1_M4$THETA$sig2)
# log-verosimilitud con parámetros estimacdos
lpyth_m4   <- sum(dt.scaled(x = y, df = 3, mean = theta_hat, sd = sqrt(sigma2_hat), log = T))
lpyth_m4
# oenalización por cantidad de parámetros
pDIC_m4    <- 2*(lpyth_m4 - mean(LP1))
pDIC_m4
# Criterio DIC
DIC_m4     <- -2*lpyth_m4 + 2*pDIC_m4
DIC_m4
```


#### modelo 5

```{r}
# log-verosimilitud
LP1 <- as.numeric(cadena1_M5$LL$ll)
# estimación theta_bayes
theta_hat  <- colMeans(cadena1_M5$THETA[,1:m])
# estimación sig2_bayes
sigma2_hat <- mean(cadena1_M5$THETA$sig2)
# log-verosimilitud con parámetros estimacdos
lpyth_m5   <- sum(dt.scaled(x = y, df = 3, mean = rep(theta_hat, nj), sd = sqrt(sigma2_hat), log = T))
lpyth_m5
# oenalización por cantidad de parámetros
pDIC_m5    <- 2*(lpyth_m5 - mean(LP1))
pDIC_m5
# Criterio DIC
DIC_m5     <- -2*lpyth_m5 + 2*pDIC_m5
DIC_m5
```

#### modelo 6

```{r}
# log-verosimilitud
LP1 <- as.numeric(cadena1_M6$LL$ll)
# estimación theta_bayes
theta_hat  <- colMeans(cadena1_M6$THETA[,1:m])
# estimación sig2_bayes
sigma2_hat <- colMeans(cadena1_M6$THETA[,(m+1):(2*m)])
# log-verosimilitud con parámetros estimacdos
lpyth_m6   <- sum(dt.scaled(x = y, df = 3, mean = rep(theta_hat, nj), sd = sqrt(rep(sigma2_hat, nj)), log = T))
lpyth_m6
# oenalización por cantidad de parámetros
pDIC_m6    <- 2*(lpyth_m6 - mean(LP1))
pDIC_m6
# Criterio DIC
DIC_m6     <- -2*lpyth_m6 + 2*pDIC_m6
DIC_m6
```
### tabla resumen

```{r}
# tabla de resumen
tab <- matrix(c(lpyth_m1, lpyth_m2, lpyth_m3, lpyth_m4, lpyth_m5, lpyth_m6,
                pDIC_m1,  pDIC_m2,  pDIC_m3,  pDIC_m4,  pDIC_m5,  pDIC_m6,
                DIC_m1,   DIC_m2,   DIC_m3,   DIC_m4,   DIC_m5,   DIC_m6),nrow = 3, ncol = 6, byrow = T)
colnames(tab) <- c("M1", "M2", "M3","M4", "M5","M6")
rownames(tab) <- c("lp","pDIC","DIC")
knitr::kable(x = tab, digits = 2, align = "c")
```

## Analisis para Bogotá D.C.

Usando el **modelo 6** obtendremos la información relacionada con **Bogotá** la cual pertenece al $n_3 = 165$ en el vector $n_j$ para $\theta$ y para $\sigma^2$.

```{r}
# theta
theta_Bog <- cadena1_M6$THETA$theta3
#sig2
sig2_Bog <- cadena1_M6$THETA$sig23
```

Para poder checar la bondad de ajuste del **modelo 6** para las siguientes estadísticas referentes al dominio de **Bogotá**:

1. Media
2. Mediana
3. Desviación estándar
4. Coefiiente de variación
5. Rango
6. Rango intercuartílico

Primero obtendremos los estáditicos observadoes para **Bogotá**, luego simularemos valores de la poblacion dados $\theta_{Bog}, \kappa$ y $\sigma^2_{Bog}$.

### datos observados

analissi previo a **Bogotá**

```{r}
# filtrar datos
Bog <- Data %>% 
      filter(Dominio == "BOGOTA")
# mirar datos
par(mfrow = c(1,2), mar = c(2.75,2.75,1.5,0.5), mgp=c(1.7,0.7,0))
boxplot(Bog$Ingtot)
plot(x = NA, y = NA, ylab = "Densidad", xlab = "Bog$ingtot", cex.axis = 0.7, xlim = range(Bog$Ingtot),ylim = c(0,0.5))
hist(Bog$Ingtot, freq = F, add = T, col = "mistyrose", border = "mistyrose")
lines(density(Bog$Ingtot), col = "red")
```

```{r}
# datos almacenados en Estadisticos
yb_Bog <- as.numeric(Estadisticos[3,3])
yb_Bog
n_Bog <- as.numeric(Estadisticos[3,2])
n_Bog
# desviación
des_Bog <- sd(Bog$Ingtot)
des_Bog
#mediana
mediana_Bog <- median(Bog$Ingtot)
mediana_Bog
#coeficiente de variación
cv_Bog <- des_Bog/yb_Bog
cv_Bog
# rango bógota
rango_Bog <- range(Bog$Ingtot)[2] - range(Bog$Ingtot)[1]
rango_Bog
# rango intercuartilico
IQR_Bog <- IQR(Bog$Ingtot)
IQR_Bog 
```

### Simulación

Haremos uso de la **Distribución predictiva posterior** para obtener las muestras de los estadisticos que nos permitan obtener el **ppp**

```{r}
#distribución predictiva posterior
yb_MCMC      <- NULL
mediana_MCMC <- NULL
des_MCMC     <- NULL
cv_MCMC      <- NULL
rango_MCMC   <- NULL
IQR_MCMC     <- NULL
#Muestreo
set.seed(1908) #año del artículo  Biometrika
for (i in 1:10000) {
      #datos
      y_pre <- rt.scaled(n = n_Bog, df = 3, mean = theta_Bog[i], sd = sqrt(sig2_Bog[i]))
      #estadisticas
      yb_MCMC[i]      <- mean(y_pre)
      mediana_MCMC[i] <- median(y_pre)
      des_MCMC[i]     <- sd(y_pre)
      cv_MCMC[i]      <- (sd(y_pre))/mean(y_pre)
      rango_MCMC[i]   <- range(y_pre)[2] - range(y_pre)[1]
      IQR_MCMC[i]     <- IQR(y_pre) 
      }
```

Con lo anterior podemos encontrar los **PPP** para cada estadístico y presentarlos en un tabla

```{r}
# tabla de resumen
tab <- matrix(c(yb_Bog, quantile(yb_MCMC,probs = 0.025), mean(yb_MCMC), quantile(yb_MCMC,probs = 0.975), mean(yb_MCMC > yb_Bog),
                mediana_Bog, quantile(mediana_MCMC,probs = 0.025), mean(mediana_MCMC), quantile(mediana_MCMC,probs = 0.975), mean(mediana_MCMC > mediana_Bog),
                des_Bog, quantile(des_MCMC,probs = 0.025), mean(des_MCMC), quantile(des_MCMC,probs = 0.975), mean(des_MCMC > des_Bog),
                cv_Bog, quantile(cv_MCMC,probs = 0.025),  mean(cv_MCMC), quantile(cv_MCMC,probs = 0.975), mean(cv_MCMC > cv_Bog),
                rango_Bog, quantile(rango_MCMC,probs = 0.025), mean(rango_MCMC), quantile(rango_MCMC,probs = 0.975), mean(rango_MCMC > rango_Bog),
                IQR_Bog, quantile(IQR_MCMC,probs = 0.025), mean(IQR_MCMC), quantile(IQR_MCMC,probs = 0.975),
                mean(IQR_MCMC > IQR_Bog)),nrow = 6, ncol = 5, byrow = T)
colnames(tab) <- c("Observado", "Q2.5%", "Estimado", "Q97.5%","PPP")
rownames(tab) <- c("Media", "Q50%", "SD","CV", "Rango","IQR")
knitr::kable(x = tab, digits = 3, align = "c")
```

## Ranking bayesiano

Usaremos el **modelo 6** para realizar un ranking bayesiano basado en las estimaciones puntuales y los intervalos de credibilidad dados para cada promedio por dominio teniendo en cuenta lo siguiente:

1. Hacer la visualización en escala logarítmica. 
2. Rojo oscuro para efectos promedio significativamente inferiores a 13.830
3. Negro para efectos promedio que no difieren significativamente de 13.830 
4. Verde oscuro para efectos promedio significativamente superiores a 13.830 
5. Observe que 13.830 corresponde a un SMLMV de 2022 en escala logarítmica.

```{r}
#ranking
THETA    <- cadena1_M6$THETA
Dominios <- Estadisticos$Dominio
#Estimaciones puntuales
that <- colMeans(THETA[,1:m])
# Int. credibilidad al 95%
IC95 <- apply(X = THETA[,1:m], MARGIN = 2, FUN = function(x) quantile(x, c(0.025,0.975)))
# ordernar el ranking (menor a mayor)
orden    <- order(that)
Dominios <- Dominios[orden]
that     <- that[orden]
IC95     <- IC95[,orden]
# Colores
colo <- rep(2,m)
colo[which(IC95[1,]>13.830)] <- 1
colo[which(IC95[2,]<13.830)] <- 3
colo <- c("green3","black","red3")[colo]
#Gráfico
par(mfrow = c(1,1), mar = c(4,10,1.5,1), mgp = c(2.5,0.75,0))
plot(NA, NA, xlab = "Ingreso total", ylab = "", main = "Ranking Bayesisano: Modelo 6", xlim = c(12.8,14.3), ylim = c(1,m), cex.axis = 0.75, yaxt = "n")
axis(side = 2, at = 1:m, labels = Dominios, las = 2, cex.axis = 0.6)
abline(v = 13.830,  col = "gray", lwd = 3)
abline(h = 1:m, col = "lightgray", lwd = 1)
# intervalo y estimación puntual
for (j in 1:m) {
  segments(x0 = IC95[1,j], y0 = j, x1 = IC95[2,j], y1 = j, col = colo[j])
  lines(x = that[j], y = j, type = "p", pch = 16, cex = 0.8, col = colo[j])
}

```

## Estimaciones para el top 5 del ranking

Usando el **modelo 6** y de acuerdo con el ranking anterior el top 5 son los  siguietnes domingos **dominios**:

1. Medellin
2. Manizales
3. Tunja
4. Bogota
5. Bucaramanga

Usaremos la **Distribución predictiva posterior** para poder estimar puntualmente  la media, la desviación estandar y el coeficiente de variación de ada dominio.

```{r}
# informacion del top 5
THETA_top5 <- THETA[,c(11, 10, 23, 3, 4, 36, 35, 48, 28, 29)]
#Estimaciones
yb_top5 <- colMeans(THETA_top5[,1:5])
sd_top5 <- sqrt(3*colMeans(THETA_top5[,6:10]))
cv_top5 <- (sd_top5/yb_top5) *100
# pasar a escala normal
yb_top5 <- exp(yb_top5)
sd_top5 <- exp(sd_top5)
# tabla de resumen
tab <- matrix(c(yb_top5[1], yb_top5[2], yb_top5[3], yb_top5[4], yb_top5[5],
                sd_top5[1], sd_top5[2], sd_top5[3], sd_top5[4], sd_top5[5],
                cv_top5[1], cv_top5[2], cv_top5[3], cv_top5[4], cv_top5[5]),nrow = 3,
              ncol = 5, byrow = T)
colnames(tab) <- c("Med", "Man", "Tun","Bog", "Buca")
rownames(tab) <- c("Media","SD","CV%")
knitr::kable(x = tab, digits = 3, align = "c")
```






